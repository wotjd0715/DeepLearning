{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNn6abKP5ZTvuw3fNXy7Wyb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"2de_EuCrszx7","colab_type":"text"},"source":["## RNN\n","이번에는 Day4에서 했던 MNIST데이터셋을 **신경망**으로 학습시켰던 것을 이번에는 **RNN**을 이용해 학습시켜봅시다.   \n","앞서 설명했듯이 RNN의 구조상 학습데이터를 단계별로 구분하여 입력해야 합니다. 즉 입력 데이를 단계별로 쪼개어 주어야 한다는 의미이므로 MNIST의 데이터 역시 쪼개어 줘야 합니다. 우리는 MNIST데이터가 28x28이니 28개로 쪼개 28x1을 28개로 만들어 총 28단계를 거쳐 넣어줄겁니다. "]},{"cell_type":"code","metadata":{"id":"U6P0orq7drZN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"3adf5e64-7d8f-4e59-d17b-9592714503ca","executionInfo":{"status":"ok","timestamp":1582998148274,"user_tz":-540,"elapsed":175726,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.examples.tutorials.mnist import input_data\n","mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot = True)\n","\n","learning_rate = 0.001\n","total_epoch = 30\n","batch_size = 128\n","\n","n_input = 28\n","n_step =28\n","n_hidden = 128\n","n_class = 10\n","\n","X = tf.placeholder(tf.float32, [None, n_step, n_input])\n","Y = tf.placeholder(tf.float32, [None, n_class])\n","\n","W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n","b = tf.Variable(tf.random_normal([n_class]))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Extracting ./mnist/data/train-images-idx3-ubyte.gz\n","Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n","Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n","Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LflBWCtItRAX","colab_type":"text"},"source":["필요한 것들을 정의 해줍시다. 기존의 신경망(Day4 MNIST.ipynb)과 달리 RNN에서는 X에 **n_step**이라는 차원하나를 추가해 줍니다.  \n","\n"," 여기서 RNN은 순서가 있는 데이터를 다루므로 한번에 입력 받을 개수와 총 몇 단계로 이뤄진 데이터를 받을지 결정해 줘야 합니다.   \n","따라서 가로픽셀수 28x1를 **n_input**으로 세로픽셀수(28단계)를 **n_step**으로 설정합니다.   \n","\n","출력값(**n_class**)은 MNIST의 분류인 0~9까지의 10개의 숫자를 원-핫 인코딩으로 표현하도록 합니다."]},{"cell_type":"code","metadata":{"id":"dEXyv1DWjf4_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"1e7f6c6c-0d79-4df0-ab10-bdfb0b747559","executionInfo":{"status":"ok","timestamp":1582997960926,"user_tz":-540,"elapsed":3384,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-3-e006f918b220>:1: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SnrpILfa1Z0I","colab_type":"text"},"source":["다음으로 n_hidden(128)개의 출력값을 갖는 RNN 셀을 생성합니다.   \n"]},{"cell_type":"code","metadata":{"id":"C7kvfreMkX-F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":196},"outputId":"f830b63a-9de3-41e9-836e-c5c3974a3f5a","executionInfo":{"status":"ok","timestamp":1582997960930,"user_tz":-540,"elapsed":2136,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["outputs, states = tf.nn.dynamic_rnn(cell,X, dtype = tf.float32)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-4-56ea447088b0>:1: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gN9GyRIm6saL","colab_type":"text"},"source":["**dynamic_rnn**함수를 이용해 RNN신경망을 완성합니다.   \n","추가로 RNN 신경망에서 나오는 출력값은 각 단계가 포함된 [batch_size, n_step, n_hidden] 형태 입니다."]},{"cell_type":"code","metadata":{"id":"PKkqAx5AkfRM","colab_type":"code","colab":{}},"source":["outputs = tf.transpose(outputs,[1,0,2])  #[batch_size, n_step, n_hidden] -> [n_step, batch_size, n_hidden]\n","outputs = outputs[-1] #[n_step, batch_size, n_hidden] -> [batch_size, n_hidden]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"usQA8hYW70In","colab_type":"text"},"source":["RNN에서 나온 출력값을 가지고 최종 출력값을 만들어 봅시다.   \n","tf.nn.softmax함수를 쓰기위해선 최종 결과값이 실측값 Y와 동일한 형태인 [batch_size,n_class]여야 합니다. 따라서 위 함수들을 이용해 outputs를 동일한 형태로 만들어 줍니다."]},{"cell_type":"code","metadata":{"id":"eaNyX40hkvMQ","colab_type":"code","colab":{}},"source":["model = tf.matmul(outputs, W)+b"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdqjFzWNkzE-","colab_type":"code","colab":{}},"source":["cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels = Y))\n","optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TsoxX3YTBnLe","colab_type":"text"},"source":["지금까지 만든 모델과 실측값을 비교하여 손실값을 구하고, 신경망을 최적화 하는 함수를 사용하여 신경망 구성을 마무리 합니다.   \n","\n","이제 앞서 구성한 신경망을 학습시키고 결과를 확인해 봅시다."]},{"cell_type":"code","metadata":{"id":"YVTYJbRjlARL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":585},"outputId":"b9d9bdd1-a812-44a2-8c61-5bb42c7468cf","executionInfo":{"status":"ok","timestamp":1582998148269,"user_tz":-540,"elapsed":184667,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","total_batch = int(mnist.train.num_examples/ batch_size)\n","\n","for epoch in range(total_epoch):\n","  total_cost = 0\n","\n","  for i in range(total_batch):\n","    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n","    batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n","\n","    _, cost_val = sess.run([optimizer,cost], feed_dict = {X: batch_xs, Y: batch_ys}) ##파이썬 인터프리터에선 마지막으로 실행된 결과값(batch_xs)이 _라는 변수에 저장된다.\n","    total_cost += cost_val\n","\n","  print('Epoch:', '%04d'%(epoch+1), 'Avg. cost =', '{:.3f}'.format(total_cost/ total_batch))\n","\n","print('최적화 완료')\n","\n","is_correct = tf.equal(tf.argmax(model,1), tf.argmax(Y,1))\n","accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n","\n","test_batch_size = len(mnist.test.images)\n","test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n","test_ys = mnist.test.labels\n","\n","print('정확도:', sess.run(accuracy, feed_dict = {X: test_xs, Y: test_ys}))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch: 0001 Avg. cost = 0.480\n","Epoch: 0002 Avg. cost = 0.210\n","Epoch: 0003 Avg. cost = 0.170\n","Epoch: 0004 Avg. cost = 0.148\n","Epoch: 0005 Avg. cost = 0.133\n","Epoch: 0006 Avg. cost = 0.125\n","Epoch: 0007 Avg. cost = 0.123\n","Epoch: 0008 Avg. cost = 0.109\n","Epoch: 0009 Avg. cost = 0.102\n","Epoch: 0010 Avg. cost = 0.102\n","Epoch: 0011 Avg. cost = 0.102\n","Epoch: 0012 Avg. cost = 0.094\n","Epoch: 0013 Avg. cost = 0.089\n","Epoch: 0014 Avg. cost = 0.086\n","Epoch: 0015 Avg. cost = 0.079\n","Epoch: 0016 Avg. cost = 0.087\n","Epoch: 0017 Avg. cost = 0.083\n","Epoch: 0018 Avg. cost = 0.072\n","Epoch: 0019 Avg. cost = 0.078\n","Epoch: 0020 Avg. cost = 0.079\n","Epoch: 0021 Avg. cost = 0.070\n","Epoch: 0022 Avg. cost = 0.071\n","Epoch: 0023 Avg. cost = 0.069\n","Epoch: 0024 Avg. cost = 0.070\n","Epoch: 0025 Avg. cost = 0.071\n","Epoch: 0026 Avg. cost = 0.066\n","Epoch: 0027 Avg. cost = 0.076\n","Epoch: 0028 Avg. cost = 0.072\n","Epoch: 0029 Avg. cost = 0.063\n","Epoch: 0030 Avg. cost = 0.060\n","최적화 완료\n","정확도: 0.9696\n"],"name":"stdout"}]}]}