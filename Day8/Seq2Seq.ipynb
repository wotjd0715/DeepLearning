{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Seq2Seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuLoI6VsQS4oFaEXdopc07"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Nlb8iSTv0GJJ","colab_type":"text"},"source":["##Seq2Seq\n","Seq2Seq에는 심볼이 필요합니다. 코드를 짜기 앞서 디코터 입력의시작, 디코더 입력의 끝, 의미없는 심볼을 각각 'S' , 'E' , 'P'로 정해두겠습니다."]},{"cell_type":"code","metadata":{"id":"YFsPe2OK0Ch_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":63},"outputId":"633ceed2-b915-467c-b3b8-e3f23d202b9a","executionInfo":{"status":"ok","timestamp":1583072639344,"user_tz":-540,"elapsed":2563,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["import tensorflow as tf\n","import numpy as np\n","\n","char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxy단어나무놀이소녀키스사랑']\n","num_dic = {n:i for i, n in enumerate(char_arr)}\n","dic_len = len(num_dic)\n","\n","seq_data = [['word','단어'],\n","            ['wood','나무'],\n","            ['game','놀이'],\n","            ['girl','소녀'],\n","            ['kiss','키스'],\n","            ['love','사랑']]"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"hsrEB9TUaa8j","colab_type":"text"},"source":["앞서 했던 것과 같이 알파벳과 우리가 쓸 한글을 넣어 줍시다."]},{"cell_type":"code","metadata":{"id":"8N24CoTF03a8","colab_type":"code","colab":{}},"source":["def make_batch(seq_data):\n","  input_batch = []\n","  output_batch = []\n","  target_batch = []\n","\n","  for seq in seq_data:\n","    input = [num_dic[n] for n in seq[0]]\n","    output = [num_dic[n] for n in ('S' + seq[1])]\n","    target = [num_dic[n] for n in (seq[1]+ 'E')]\n","\n","    input_batch.append(np.eye(dic_len)[input])\n","    output_batch.append(np.eye(dic_len)[output])\n","    target_batch.append(target)\n","\n","  return input_batch, output_batch, target_batch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGw99_GWarrZ","colab_type":"text"},"source":["```python\n","input = [num_dic[n] for n in seq[0]]\n","```\n","인코더 셀의 입력값을 위해 입력 단어를 한 글자씩 데어 배열로 만듭니다.\n","\n","```python\n"," output = [num_dic[n] for n in ('S' + seq[1])]\n"," ```\n"," 디코더 셀의 입력값을 위해 출력 단어의 글자들릉ㄹ 배열로 만들고, 시작을 나타내는 심볼 'S'를 맨 앞에 붙입니다.\n","\n"," ```python\n","  target = [num_dic[n] for n in (seq[1]+ 'E')]\n","```\n","학습을 위해 비교할 디코더 셀의 출력값을 만들고, 출력의 끝을 알려주는 심볼 'E'를 마지막에 붙입니다.\n"]},{"cell_type":"code","metadata":{"id":"hRMWBbwR182j","colab_type":"code","colab":{}},"source":["learning_rate = 0.01\n","n_hidden = 128\n","total_epoch = 100\n","\n","n_class = n_input = dic_len"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zx5IOIGdbr_h","colab_type":"text"},"source":["다음으로 신경망 모델에서 사용할 하이퍼 파라미터, placeholder, 입출력 변수용 수치들을 정의 합니다."]},{"cell_type":"code","metadata":{"id":"3Isqo4GH2GLU","colab_type":"code","colab":{}},"source":["enc_input = tf.placeholder(tf.float32, [None,None, n_input])\n","dec_input = tf.placeholder(tf.float32, [None,None, n_input])\n","targets = tf.placeholder(tf.int64, [None,None])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDvBGzeucS0x","colab_type":"text"},"source":["RNN의 특성상 입력데이터의 단계가 있습니다. 또한 입력값들은 원-핫 인코딩을 사용하고 디코더의 출력값은 인덱스 숫자를 그대로 사용하기 때문에 입력값의 차원이 하나더 높습니다.    \n","입력 형식: [batch size, time steps, input size]   \n","출력 형식: [batch size, time steps]"]},{"cell_type":"code","metadata":{"id":"_MtJTBfO24B3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"74959ea6-7c81-4bf7-c36a-f87c22e386a8","executionInfo":{"status":"ok","timestamp":1583072640032,"user_tz":-540,"elapsed":1802,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["with tf.variable_scope('encode'):\n","  enc_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n","  enc_cell = tf.nn.rnn_cell.DropoutWrapper(enc_cell, output_keep_prob=0.5)\n","\n","  outputs, enc_states = tf.nn.dynamic_rnn(enc_cell, enc_input, dtype= tf.float32)\n","\n","with tf.variable_scope('decode'):\n","  dec_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n","  dec_cell = tf.nn.rnn_cell.DropoutWrapper(dec_cell, output_keep_prob = 0.5)\n","\n","  outputs , dec_states = tf.nn.dynamic_rnn(dec_cell, dec_input, initial_state=enc_states, dtype= tf.float32)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-5-88a393877293>:2: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From <ipython-input-5-88a393877293>:5: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.add_weight` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HgxmpU95dREc","colab_type":"text"},"source":["Seq2Seq은 인코더와 디코더로 구분되므로 cell역시 인코더 셀과 디코더 셀을 구분하여 만들어야 합니다.   \n","셀은 기본셀(BasicLSTMCell)을 사용 하였고 각 셀에 드롭아웃도 적용했습니다.   \n","주의할 점은 디코더의 초기 상태 값(**입력값 아님**)으로 인코더의 최종 상태 값을 넣어줘야 한다는 것입니다.(**initial_state = enc_states**)\n"]},{"cell_type":"code","metadata":{"id":"of8cmubj3ycf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":143},"outputId":"e5ab42d8-3b35-4def-b7c6-90bbbc441b02","executionInfo":{"status":"ok","timestamp":1583072645387,"user_tz":-540,"elapsed":1934,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["model = tf.layers.dense(outputs, n_class, activation = None)\n","cost = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits = model, labels = targets))\n","\n","optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-6-2ace2f221404>:1: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zBdSb5KIejLZ","colab_type":"text"},"source":["출력층을 만들고 손실함수와 최적화 함수를 구성합니다.   \n","출력층은 layer모듈의 dense 함수를 사용하였습니다.   \n","Dense 를 사용할시: output = activation(dot(input, kernel) + bias)   \n","고수준의 API를 사용하면 가중치와 편향을 설정하지 않고도 알아서 처리해줍니다."]},{"cell_type":"code","metadata":{"id":"BglLkyOT4JBw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1f82565d-c80b-4132-c7b8-dac6aeebcc16","executionInfo":{"status":"ok","timestamp":1583062801335,"user_tz":-540,"elapsed":2279,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["sess = tf.Session()\n","sess.run(tf.global_variables_initializer())\n","\n","input_batch, output_batch, targets_batch = make_batch(seq_data)\n","\n","for epoch in range(total_epoch):\n","  _,loss = sess.run([optimizer, cost], feed_dict= {enc_input: input_batch, dec_input: output_batch, targets: targets_batch})\n","\n","  print('Epoch:', '%04d' %(epoch+1), 'cost=', '{:.6f}'.format(loss))\n","\n","print('최적화 완료')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch: 0001 cost= 3.687104\n","Epoch: 0002 cost= 3.570867\n","Epoch: 0003 cost= 3.356566\n","Epoch: 0004 cost= 2.936076\n","Epoch: 0005 cost= 2.368010\n","Epoch: 0006 cost= 2.318052\n","Epoch: 0007 cost= 2.006325\n","Epoch: 0008 cost= 1.834133\n","Epoch: 0009 cost= 1.913274\n","Epoch: 0010 cost= 1.598610\n","Epoch: 0011 cost= 1.458591\n","Epoch: 0012 cost= 1.159043\n","Epoch: 0013 cost= 1.177838\n","Epoch: 0014 cost= 0.867390\n","Epoch: 0015 cost= 0.856701\n","Epoch: 0016 cost= 0.778134\n","Epoch: 0017 cost= 0.703400\n","Epoch: 0018 cost= 0.583874\n","Epoch: 0019 cost= 0.409060\n","Epoch: 0020 cost= 0.540391\n","Epoch: 0021 cost= 0.343857\n","Epoch: 0022 cost= 0.348853\n","Epoch: 0023 cost= 0.265001\n","Epoch: 0024 cost= 0.411350\n","Epoch: 0025 cost= 0.267568\n","Epoch: 0026 cost= 0.349986\n","Epoch: 0027 cost= 0.183616\n","Epoch: 0028 cost= 0.325890\n","Epoch: 0029 cost= 0.154015\n","Epoch: 0030 cost= 0.198595\n","Epoch: 0031 cost= 0.139012\n","Epoch: 0032 cost= 0.121018\n","Epoch: 0033 cost= 0.202327\n","Epoch: 0034 cost= 0.194385\n","Epoch: 0035 cost= 0.086881\n","Epoch: 0036 cost= 0.119560\n","Epoch: 0037 cost= 0.092934\n","Epoch: 0038 cost= 0.096200\n","Epoch: 0039 cost= 0.160486\n","Epoch: 0040 cost= 0.062336\n","Epoch: 0041 cost= 0.064000\n","Epoch: 0042 cost= 0.066818\n","Epoch: 0043 cost= 0.020908\n","Epoch: 0044 cost= 0.024418\n","Epoch: 0045 cost= 0.036392\n","Epoch: 0046 cost= 0.034153\n","Epoch: 0047 cost= 0.077540\n","Epoch: 0048 cost= 0.033805\n","Epoch: 0049 cost= 0.041394\n","Epoch: 0050 cost= 0.022317\n","Epoch: 0051 cost= 0.016651\n","Epoch: 0052 cost= 0.012559\n","Epoch: 0053 cost= 0.013389\n","Epoch: 0054 cost= 0.025140\n","Epoch: 0055 cost= 0.015422\n","Epoch: 0056 cost= 0.010219\n","Epoch: 0057 cost= 0.012230\n","Epoch: 0058 cost= 0.016964\n","Epoch: 0059 cost= 0.015732\n","Epoch: 0060 cost= 0.005159\n","Epoch: 0061 cost= 0.008063\n","Epoch: 0062 cost= 0.007899\n","Epoch: 0063 cost= 0.005678\n","Epoch: 0064 cost= 0.005733\n","Epoch: 0065 cost= 0.021819\n","Epoch: 0066 cost= 0.007311\n","Epoch: 0067 cost= 0.008543\n","Epoch: 0068 cost= 0.009990\n","Epoch: 0069 cost= 0.007810\n","Epoch: 0070 cost= 0.014204\n","Epoch: 0071 cost= 0.006641\n","Epoch: 0072 cost= 0.003612\n","Epoch: 0073 cost= 0.002413\n","Epoch: 0074 cost= 0.006971\n","Epoch: 0075 cost= 0.008660\n","Epoch: 0076 cost= 0.014041\n","Epoch: 0077 cost= 0.009957\n","Epoch: 0078 cost= 0.003307\n","Epoch: 0079 cost= 0.006425\n","Epoch: 0080 cost= 0.005008\n","Epoch: 0081 cost= 0.010034\n","Epoch: 0082 cost= 0.005219\n","Epoch: 0083 cost= 0.008309\n","Epoch: 0084 cost= 0.006251\n","Epoch: 0085 cost= 0.005154\n","Epoch: 0086 cost= 0.005033\n","Epoch: 0087 cost= 0.004546\n","Epoch: 0088 cost= 0.003021\n","Epoch: 0089 cost= 0.008120\n","Epoch: 0090 cost= 0.001687\n","Epoch: 0091 cost= 0.010864\n","Epoch: 0092 cost= 0.002562\n","Epoch: 0093 cost= 0.004853\n","Epoch: 0094 cost= 0.001907\n","Epoch: 0095 cost= 0.001841\n","Epoch: 0096 cost= 0.004350\n","Epoch: 0097 cost= 0.006615\n","Epoch: 0098 cost= 0.005041\n","Epoch: 0099 cost= 0.001731\n","Epoch: 0100 cost= 0.003268\n","최적화 완료\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ORmzG8G35StH","colab_type":"code","colab":{}},"source":["def translate(word):\n","  seq_data = [word,'P'*len(word)]\n","\n","  input_batch, output_batch, targets_batch = make_batch([seq_data])\n","\n","  prediction = tf.argmax(model,2)\n","\n","  result = sess.run(prediction, feed_dict= {enc_input: input_batch, dec_input: output_batch, targets: targets_batch})\n","\n","  decoded = [char_arr[i] for i in result[0]]\n","\n","  end = decoded.index('E')\n","  translated = ''.join(decoded[:end])\n","  return translated"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pHElGG2ui0LN","colab_type":"text"},"source":["이 모델은 입력값과 출력값 데이터로 [영어단어, 한글뜻]를 사용하지만 예측시에는 한글뜻을 모르므로 디코더의 입출력을 의미없는 값인 'P'로 채워 데이터를 구성합니다.   \n","input_batch는 [ 'w', 'o', 'r', 'd']   \n","output_batch는 [ 'P, 'P', 'P', 'P'] 글자들의 인덱스를 원-핫 인코딩한 값   \n","target_batch는 [ 'P, 'P', 'P', 'P'] 의 각 글자의 인덱스인 [2, 2, 2, 2]가 됩니다.   \n","\n","그리고 예측모델을 돌립니다. 세번재 차원을 argmax로 취해 가장 확률이 높은 글자(의 인덱스)를 예측값으로 만듭니다. 세번재 차원을 argmax로 취하는 이유는 결과값이 [batch_size, time steps, input size]형태로 나오기 때문입니다.\n"]},{"cell_type":"code","metadata":{"id":"1ciIfW_P59-3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"outputId":"525917a9-21e4-4a36-c69d-8193bf20ff52","executionInfo":{"status":"ok","timestamp":1583063093543,"user_tz":-540,"elapsed":1878,"user":{"displayName":"박재성","photoUrl":"","userId":"11555028975514250151"}}},"source":["print('\\n===번역테스트===')\n","print('word ->', translate('word'))\n","print('wodr ->', translate('wodr'))\n","print('love ->', translate('love'))\n","print('loev ->', translate('loev'))\n","print('abcd ->', translate('abcd'))\n","print('gisl ->', translate('gisl'))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["\n","===번역테스트===\n","word -> 단어\n","wodr -> 나어\n","love -> 사랑\n","loev -> 사랑\n","abcd -> 놀이\n","gisl -> 소녀\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"txzXyHahk0pN","colab_type":"text"},"source":["학습시킨 단어와 약간의 오타에도 그럴듯 하게 번역이 되었습니다.   \n","또한 이상한 단어에도 연관 없어보이지만 그럴듯한 결과를 추측하였습니다.   \n","이 모델에서 글자들을 단어로 바꾸기만 하면 문장 단위의 번역을, 그 후 입력을 질문으로, 출력을 답변으로 하는 데이터를 학습시키면 챗봇을 만들 수 있습니다."]}]}